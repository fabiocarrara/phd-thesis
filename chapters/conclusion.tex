%============================= INTRODUCTION =================================

\chapter{Conclusions}
\label{ch:conclusion}

Empowering machines with visual perception abilities can help us managing and exploring the exponentially growing amount of digital visual data produced every day.
In this context, novel AI techniques based on \acrlong{dl} are currently enabling high-quality computer vision thanks to their ability to learn from data effective high-level representations of visual data.
Specifically, \acrfullpl{cnn} shown impressive results in recent research of visual perception and representation, and its adoption improved the state of the art in many vision related tasks, including large-scale image understanding and content-based image retrieval.

In this thesis, we investigate and enhance the usability of \glspl{cnn} for visual data management.
In particular,
\begin{itemize}
    \item we identified and proposed mitigations to three common and general limitations belonging to \glspl{cnn} usage, namely the high computational cost, the high data labeling cost, and the poor robustness to out-of-distribution data, and
    \item we propose practical solutions to integrate \gls{cnn}-based content-based image retrieval in the primarily used textual-search paradigm by %
i) enabling text-based image search in unlabeled sets of images, and %
ii) adopting surrogate text representations of images to index them in existing textual search engines technologies.
\end{itemize}

\ref{ch:introduction,ch:background} provides an introduction and background knowledge about \acrlong{dl}, \glspl{cnn}, and their usage in the context of visual data understanding and retrieval.
\ref{ch:miniaturization,ch:cross-media,ch:adversarial} tackles respectively three drawbacks of \gls{cnn}, propose practical solutions, and experimentally evaluate them in the context of image classification tasks.

Specifically, \ref{ch:miniaturization} tackles the problem of the high computational cost usually required by deep models, and thus its limited usability in resource-bounded devices.
We investigate of the reduction of \glspl{cnn} architectures to enable edge computing in low-resources embedded devices.
We proposed a miniaturized version of the famous AlexNet image classifier, named mAlexNet, tailored to smart camera devices.
The designed architecture has two orders of magnitude fewer parameters, and on the tested smart camera hardware (i.e., Raspberry Pi), it delivers a two order of magnitude more throughput in terms of images classified per second.
We extensively evaluated our proposed architecture on the task of decentralized parking lot visual occupancy detection, which served as an instance of problems that largely benefit from an edge computing paradigm and the robust visual perception offered by \glspl{cnn}.
We collected and published a novel dataset for parking lot visual occupancy detection, named CNRPark-EXT, which includes challenging patterns such as highly occluded slots, and daily and seasonal light changes,
Experiments on multiple datasets showed that our architecture outperforms state-of-the-art techniques (which at the time did not leverage learned features) both in terms of accuracy and generalization to unseen situations while incurring only in a slight degradation of the generalization performance compared to the fully featured AlexNet architecture.

In \ref{ch:cross-media}, we propose and evaluate an automated pipeline to train image classifiers drastically limiting the cost of data labeling by exploiting weakly-labeled data scraped from the Web.
In particular, we exploit the co-occurrence of textual and visual data in social media posts and adopt a student-teacher cross-media learning approach in which a model relying on textual data provide supervision to a visual classifier without manual label assignments.
We demonstrated the potential of the proposed approach in the specific task of visual sentiment analysis, in which good image labels are particularly expensive to obtain.
We collected from the Twitter social media platform a large-scale dataset of text-and-image tweets and used a pre-trained textual sentiment predictor to assign a noisy sentiment to the correspondent images, thus automatically creating a huge noisy dataset for visual sentiment classification at a precedently unmet scale.
We argued that the vast amount of data obtainable from the Web compensates for the noisy labels and produces better classifiers in the long run.
We showed through experimental evaluation that \glspl{cnn} trained on this dataset outperform state-of-the-art visual sentiment predictors trained on small manually labeled data.

In \ref{ch:adversarial}, we investigated a diffuse problem of \gls{ml}-based models, that is, the vulnerability to evasion attacks through adversarial examples.
Adversarial examples represent a particular set of out-of-distribution inputs which looks like a valid, authentic input but instead produces an unexpected behavior of the model that can be exploited by an attacker, e.g., to bypass content-moderation filters or induce a reaction in \gls{ml}-based agents.
In the case of images, adversarial perturbations are small, often imperceptible distortions crafted and added to an authentic input to lead the model to misclassify it with high confidence.
This easily exploitable vulnerability mainly derives from the low robustness of models to points belonging to underrepresented parts of input space.
We proposed a general detection scheme for adversarial images to counteract possible evasion attacks to image classifiers implemented with \glspl{cnn}.
Exploiting the distribution of internal activations of the network of training images, we adopted kNN classifiers to generate an authenticity score of the classification given by the attacked classifier that we employed to discern adversarial examples from authentic ones.
Experiments on multiple \glspl{cnn} architectures and on multiple adversarial generation algorithms showed we are able to detect roughly 80\% of adversarial examples while retaining roughly 90\% of authentic images in zero-knowledge attacks.